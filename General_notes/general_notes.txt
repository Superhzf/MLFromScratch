1.Q: Why vectorization is faster than loops?
A:

2. Q: Difference between multiplication functions in NumPy?
A: np.multiply(a, b), element-wise multiplication
np.dot(a, b) == np.matmul(a, b) == a @ b, matrix multiplication

3. Q: What is the difference between NumPy max and NumPy maximum?
A: np.max only works on a single input array and finds the value of maximum
element in that entire array. Alternatively, it takes an axis argument and will
find the maximum value along axis of the input array.
np.maximum is to take two arrays and compute their element-wise maximum

4. Q: What is the relationship between OLS and gradient descent?
A: OLS is an analytical approach which means the problem has an closed form solution,
whereas gradient descent is an iterative method.

5. Q: Why is gradient descent often used compared to OLS?
A: Because 1. some problems do not have a closed form solution. 2. gradient descent
is computationally cheaper, in order to solve a problem using OLS, we may have to
calculate the matrix multiplication and invert matrix, they are very expensive.
3. gradient descent does not need to meet strict assumptions like no multicollinearity.

6. Q: Why is second-order optimization algorithms, such as Newton's method not as
widely used as stochastic gradient descent in machine learning problems?
A: TODO

7. I tested NAG optimization with the help of PyTorch (https://pytorch.org/docs/stable/optim.html#torch.optim.SGD)
Assuming the PyTorch implement is correct, SGD with nesterov=True is very unstable. The loss changes drastically.
Whereas, the regular SGD with momentum works pretty well. So I decided not to implement
the NAG algorithm.
One good reference: https://fyubang.com/2019/08/10/optimizer_sgd/.
It is said that SGD with NAG is well suited for RNN, I will test this when I come to
RNN

8. Q: What is the difference between local maxima/minima and saddle point?
ref :https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/optimizing-multivariable-functions/a/maximums-minimums-and-saddle-points
ref: https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/optimizing-multivariable-functions/a/second-partial-derivative-test
A: When the function is continuous and differentiable, points where make the first
order derivative equal to zero are stable points, critical points, and stationary points.
When the second order is not zero they are local maxima/minima.
Inflection points are those make the second order derivative equal to zero.
Saddle points are specific for multivariable functions, when the first order derivative
is zero and the second order derivative is not zero, at the same time, different
axes disagree over whether this input should be a maximum or minimum. For example,
f = x^2+y^2, (0, 0) makes the first derivative zero and the second derivative not zero.
However, when I move in the x direction, (0,0) is the local minimum, but if I move in
the y direction, (0, 0) is the local maximum, so x and y axes disagree with each
other.

Formally, x is a minimum point of f it there is some small (ball shaped) region
in the input space around the point x, such that the highest possible value you can
get for f evaluated on points in that region is achieved at the point x.

To determine whether a point is a local minimum/maximum or saddle point, for example if
we have two variables, first find points which make the first order derivative zero,
then calculate H = Fxx*Fyy - Fxy^2, if H < 0, then it's a saddle point, if H > 0,
if fxx < 0, it's a local maximum point else it's a local minimum point. For example,
F = x^2 + y ^ 2 + pxy and point (0, 0), when p = 4, if |p| > 2, (0, 0) is a saddle
point, else (0, 0) is a global minimum.

9. Q: Maximize F = (x^2)*y, s.t. x^2 + y^2 = b
A: One solution is replace x^2 with 1 - y^2 and let the first order derivative equal to 0.
But it does not work if functions are complicated. ref: http://www.economicsdiscussion.net/essays/economics/constrained-optimisation-substitution-method-lagrange-multiplier-technique-and-lagrangian-multiplier/865
The second solution is using Lagrange multiplier. This is a classic constrained
optimization problem.The idea is if we draw the contour lines of f = (x^2)*y, those
contour lines will interact with x^2+y^1=1, after checking out different contour
lines, it is obvious that the tangent contour lines give us the largest f value.
It means the gradient at that point is perpendicular to both curves (f and x^2+y^2=1).
The gradient of f and the gradient of x^2+y^2 are proportional.
Therefore, we have:
If we let G = x^2+y^2, F = (x^2)*y, then
deltaF(Xm, Ym) = lambda*deltaG(Xm, Ym), lambda is a Lagrange multiplier.
This equation represents when the contour line of one function is tangent to the
contour line of the other.

delta(Xm, Ym) = lambda*delta(Xm, Ym), x^2+y^2=1 <=> 2xy = lambda*2x, x^2 = lambda * 2y, x^2+y^2=1
<=> x = sqrt(2/3), y = sqrt(1/3)

Repackage it, we get The Lagrangian function: L(x, y, lambda) = F - lambda * (G - b),
if we calculate all the partial derivatives of L and let them equal to 0,
then we get the same thing as above. Now, L becomes an unconstrained problem! We
could just set the gradient to 0.

10: Q: What is the physical interpretation of the Lagrange multiplier?
A: Suppose we want to maximize F = (x^2)*y s.t. x^2+y^2 = b, them lambda means that
increasing b by 1 unit, then F will be increased by lambda units.
ref. about Lagrange multiplier: https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives

11. Q: What if we have multiple (more than 1) constraints?
A: The Lagrange multiplier method can be generalized into unlimited number of
constraints. For example, please refer to multiLarange.pdf

12. Q: What is the advantage of LogSoftMax over the regular SoftMax?
A: LogSoftMax + mean (in PyTorch it is nn.NLLoss) == SoftMax + cross entropy loss.
So, LogSoftMax is equal to SoftMax + cross entropy loss numerically. Whereas, doing
these two operations separately is slow and not numerically stable. I don't
understand why Logsoftmax is more stable. It is said that if we calculate
as a whole, the middle stages would not be saved.
